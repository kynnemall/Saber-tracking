{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf81c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imutils.video import FileVideoStream\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "np.seterr(divide='ignore') # ignore divide by zero when calculating angle\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8524c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Hough Line detection\n",
    "rho = 1                 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180     # angular resolution in radians of the Hough grid\n",
    "threshold = 40          # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 25    # minimum number of pixels making up a line\n",
    "max_line_gap = 10       # maximum gap in pixels between connectable line segments\n",
    "WIDTH = 720             # width to resize the processed video to\n",
    "\n",
    "def resize(img):\n",
    "    return cv2.resize(img, (WIDTH, WIDTH))\n",
    "\n",
    "def process_video(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    ret, frame = cap.read()\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.parquet\")\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        # these channels were swapped in the notebook\n",
    "        b = (frame[:, :, 2] > 200).astype(int)\n",
    "        r = (frame[:, :, 0] > 220).astype(int)\n",
    "\n",
    "        # convert to HSV for more masking options\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = (hsv[:, :, 2] > 210).astype(int)\n",
    "        s = cv2.inRange(hsv[:, :, 1],  140, 175)\n",
    "\n",
    "        # combine masks into one\n",
    "        m1 = np.logical_and(b, s)\n",
    "        m2 = np.logical_and(r, v)\n",
    "        mask = (m1 + m2).astype(np.uint8)\n",
    "\n",
    "        # Run Hough on edge detected image\n",
    "        # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "        lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "        # process lines\n",
    "        if isinstance(lines, np.ndarray):\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line.ravel()                   \n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                x_diff = x1 - x2\n",
    "                y_diff = y1 - y2\n",
    "                length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                edge_x = 200 < centroid[0] < 1080\n",
    "                edge_y = 100 < centroid[1] < 620\n",
    "                if 100 > length > 30 and edge_x and edge_y: # length of 25 or 30\n",
    "                    degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                    data[\"frame\"].append(frame_num)\n",
    "                    data[\"centroid_x\"].append(centroid[0])\n",
    "                    data[\"centroid_y\"].append(centroid[1])\n",
    "                    data[\"angle\"].append(degrees)\n",
    "                    data[\"length\"].append(length)\n",
    "\n",
    "        # perform clustering to reduce data\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.shape[0] > 0:\n",
    "            db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]])\n",
    "            df[\"labels\"] = db.labels_\n",
    "            df = df.query(\"labels != -1\")\n",
    "            if df.shape[0] > 0:\n",
    "                df = df.groupby([\"frame\", \"labels\"], as_index=False)[[\"centroid_x\", \"centroid_y\", \"angle\"]].mean()\n",
    "                for centroid in df[[\"centroid_x\", \"centroid_y\"]].values:\n",
    "                    cv2.drawMarker(frame, centroid.astype(int), (0, 255, 0), markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "        if save_stats:\n",
    "            # Create a parquet table from your dataframe\n",
    "            table = pa.Table.from_pandas(df)\n",
    "\n",
    "            # Write direct to your parquet file\n",
    "            pq.write_to_dataset(table, root_path=output_path)\n",
    "            \n",
    "            # reset data structure\n",
    "            data = {\"frame\" : [],\n",
    "                    \"centroid_x\" : [],\n",
    "                    \"centroid_y\" : [],\n",
    "                    \"angle\" : [],\n",
    "                    \"length\" : []}\n",
    "\n",
    "        resized = resize(frame)\n",
    "        \n",
    "        if show_video:\n",
    "            cv2.imshow(\"Frame\", resized)\n",
    "        if save_video:\n",
    "            out.write(resized)\n",
    "        frame_num += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) # wait until any key is pressed\n",
    "        if frame_limit and frame_num == 500:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f process_video process_video(\"test_video.mp4\", True, \"min_length_30.avi\", False, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfdf44",
   "metadata": {},
   "source": [
    "Base function took 62 seconds to run on 500 frames (8 FPS) when `save_stats=False`; only 17 seconds when `save_stats=True` (29.4 FPS). Odd behaviour indeed.\n",
    "\n",
    "Results when saving stats:\n",
    "* 3.1 seconds (18.8%) masking with numpy\n",
    "* 0.821 seconds (5.1%) processing lines\n",
    "* 5.8 seoncds (36.8%) on clustering and DataFrame reduction\n",
    "* 0.75 seconds (4.7%) making a Parquet table and writing to file\n",
    "* The rest taken by optimized OpenCV functions\n",
    "\n",
    "These processes account for ~62% of the time taken. I think it may be possible to reduce total time taken by a third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fa103",
   "metadata": {},
   "source": [
    "### Optimizations to implement\n",
    "Use threading as per [link](https://pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) to queue frames for reading and theoretically increase FPS by ~50% (according to article). This [article](https://towardsdatascience.com/lightning-fast-video-reading-in-python-c1438771c4e6) may also be of use in increasing read speed. Alternatively, multiprocessing may work as in this [blog post](https://xailient.com/blog/parallel-processing-using-python-for-faster-video-processing/) since it also covers writing the frames as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4896c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex.cluster import DBSCAN\n",
    "\n",
    "# parameters for Hough Line detection\n",
    "RHO = 1                 # distance resolution in pixels of the Hough grid\n",
    "THETA = np.pi / 180     # angular resolution in radians of the Hough grid\n",
    "THRESHOLD = 20          # minimum number of votes (intersections in Hough grid cell)\n",
    "MIN_LINE_LENGTH = 5    # minimum number of pixels making up a line\n",
    "MAX_LINE_GAP = 2       # maximum gap in pixels between connectable line segments\n",
    "WIDTH = 720             # width to resize the processed video to\n",
    "\n",
    "def optimized(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    ret, frame = cap.read()\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.csv\")\n",
    "    # prevent appending to existing file\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (frame.shape[1] // 2, frame.shape[0] // 2))\n",
    "            # these channels were swapped in the notebook\n",
    "            b = cv2.inRange(frame[:, :, 2], 200, 255)\n",
    "            r = cv2.inRange(frame[:, :, 0], 180, 255)\n",
    "\n",
    "            # convert to HSV for more masking options\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            v = cv2.inRange(hsv[:, :, 2], 170, 255)\n",
    "            s = cv2.inRange(hsv[:, :, 1], 140, 175)\n",
    "\n",
    "            # combine masks into one\n",
    "            m1 = cv2.bitwise_and(b, s)\n",
    "            m2 = cv2.bitwise_and(r, v)\n",
    "            mask = cv2.bitwise_or(m1, m2)\n",
    "\n",
    "            # Run Hough on masked image\n",
    "            # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "            lines = cv2.HoughLinesP(mask, RHO, THETA, THRESHOLD, np.array([]), MIN_LINE_LENGTH, MAX_LINE_GAP)\n",
    "\n",
    "            # process lines\n",
    "            if isinstance(lines, np.ndarray):\n",
    "                for line in lines:\n",
    "                    x1, y1, x2, y2 = line.ravel()\n",
    "                    centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                    x_diff = x1 - x2\n",
    "                    y_diff = y1 - y2\n",
    "                    length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                    edge_x = 100 < centroid[0] < 540\n",
    "                    edge_y = 50 < centroid[1] < 310\n",
    "                    l = 50 > length > 10\n",
    "                    if l and edge_x and edge_y: # length of 25 or 30\n",
    "                        degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                        data[\"frame\"].append(frame_num)\n",
    "                        data[\"centroid_x\"].append(centroid[0])\n",
    "                        data[\"centroid_y\"].append(centroid[1])\n",
    "                        data[\"angle\"].append(degrees)\n",
    "                        data[\"length\"].append(length)\n",
    "\n",
    "            # perform clustering to reduce data\n",
    "            df = pd.DataFrame(data)\n",
    "            if df.shape[0] > 0:\n",
    "                df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]].values).labels_\n",
    "                df = df[(df != -1).all(axis=1)]\n",
    "                if df.shape[0] > 0:\n",
    "                    df = df.groupby(\"labels\", as_index=False, sort=False).mean()\n",
    "                    for cx, cy in zip(df[\"centroid_x\"], df[\"centroid_y\"]):\n",
    "                        cv2.drawMarker(frame, (int(cx), int(cy)), (0, 255, 0), markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "            if save_stats:\n",
    "                df.to_csv(output_path, index=False, mode='a',\n",
    "                            header=not os.path.exists(output_path))\n",
    "\n",
    "                # reset data structure\n",
    "                data = {\"frame\" : [],\n",
    "                        \"centroid_x\" : [],\n",
    "                        \"centroid_y\" : [],\n",
    "                        \"angle\" : [],\n",
    "                        \"length\" : []}\n",
    "\n",
    "            resized = cv2.resize(frame, (WIDTH, WIDTH))\n",
    "\n",
    "            if show_video:\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "            if save_video:\n",
    "                out.write(resized)\n",
    "            frame_num += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            if key == ord('p'):\n",
    "                cv2.waitKey(-1) # wait until any key is pressed\n",
    "            if frame_limit and frame_num == 500:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7f65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses same default params as \n",
    "\n",
    "def optimized_fvs(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    # use OpenCV to get total frames\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    \n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.csv\")\n",
    "    # prevent appending to existing file\n",
    "    exists = os.path.exists(output_path)\n",
    "    if exists:\n",
    "        os.remove(output_path)\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "    \n",
    "    # start imutils streaming\n",
    "    fvs = FileVideoStream(fname, queue_size=250).start()\n",
    "\n",
    "    while fvs.more():\n",
    "        frame = fvs.read()\n",
    "        if isinstance(frame, np.ndarray):\n",
    "            frame = cv2.resize(frame, (frame.shape[1] // 2, frame.shape[0] // 2))\n",
    "            # these channels were swapped in the notebook\n",
    "            b = cv2.inRange(frame[:, :, 2], 200, 255)\n",
    "            r = cv2.inRange(frame[:, :, 0], 180, 255)\n",
    "\n",
    "            # convert to HSV for more masking options\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            v = cv2.inRange(hsv[:, :, 2], 170, 255)\n",
    "            s = cv2.inRange(hsv[:, :, 1], 140, 175)\n",
    "\n",
    "            # combine masks into one\n",
    "            m1 = cv2.bitwise_and(b, s)\n",
    "            m2 = cv2.bitwise_and(r, v)\n",
    "            mask = cv2.bitwise_or(m1, m2)\n",
    "\n",
    "            # Run Hough on masked image\n",
    "            # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "            lines = cv2.HoughLinesP(mask, RHO, THETA, THRESHOLD, np.array([]), MIN_LINE_LENGTH, MAX_LINE_GAP)\n",
    "\n",
    "            # process lines\n",
    "            if isinstance(lines, np.ndarray):\n",
    "                for line in lines:\n",
    "                    x1, y1, x2, y2 = line.ravel()\n",
    "                    centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                    x_diff = x1 - x2\n",
    "                    y_diff = y1 - y2\n",
    "                    length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                    edge_x = 100 < centroid[0] < 540\n",
    "                    edge_y = 50 < centroid[1] < 310\n",
    "                    l = 50 > length > 10\n",
    "                    if l and edge_x and edge_y: # length of 25 or 30\n",
    "                        degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                        data[\"frame\"].append(frame_num)\n",
    "                        data[\"centroid_x\"].append(centroid[0])\n",
    "                        data[\"centroid_y\"].append(centroid[1])\n",
    "                        data[\"angle\"].append(degrees)\n",
    "                        data[\"length\"].append(length)\n",
    "\n",
    "            # perform clustering to reduce data\n",
    "            df = pd.DataFrame(data)\n",
    "            if df.shape[0] > 0:\n",
    "                df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]].values).labels_\n",
    "                df = df[(df != -1).any(axis=1)]\n",
    "                if df.shape[0] > 0:\n",
    "                    df = df.groupby(\"labels\", as_index=False, sort=False).mean()\n",
    "                    for cx, cy in zip(df[\"centroid_x\"], df[\"centroid_y\"]):\n",
    "                        cv2.drawMarker(frame, (int(cx), int(cy)), (0, 255, 0), markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "            if save_stats:\n",
    "                df.to_csv(output_path, mode='a', header=not exists)\n",
    "\n",
    "                # reset data structure\n",
    "                data = {\"frame\" : [],\n",
    "                        \"centroid_x\" : [],\n",
    "                        \"centroid_y\" : [],\n",
    "                        \"angle\" : [],\n",
    "                        \"length\" : []}\n",
    "\n",
    "            resized = cv2.resize(frame, (WIDTH, WIDTH))\n",
    "\n",
    "            if show_video:\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "            if save_video:\n",
    "                out.write(resized)\n",
    "            frame_num += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            if key == ord('p'):\n",
    "                cv2.waitKey(-1) # wait until any key is pressed\n",
    "            if frame_limit and frame_num == 500:\n",
    "                break\n",
    "\n",
    "    fvs.stop()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd643001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f optimized optimized(\"test_video.mp4\", True, \"min_length_30.avi\", False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3caa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 33838/33838 [12:01<00:00, 46.92it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f optimized_fvs optimized_fvs(\"test_video.mp4\", True, \"min_length_30.avi\", False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43601d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(FileVideoStream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a73bf",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "* Removed resize function and included in main function body\n",
    "* Replacing Parquet with Pandas CSV reduces stats saving time from 0.75 to 0.375 seconds\n",
    "* Replacing numpy masking with OpenCV functions reduces masking time from 3.1 to 0.993 seconds!\n",
    "* Replacing Pandas query with `df[df[col] != value]` reduces time from 1.7 to 0.452 seconds!\n",
    "* Removing the `frame` column as an index (since it's constant) reduces time from 1.7 to 1.2 seconds\n",
    "* Fitting DBSCAN with `.values` rather than a `DataFrame` reduces time from 1.73 to 1.14 seconds\n",
    "* Using `sklearnex` reduced DBSCAN fitting time from 1.52 to 1.14 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa7181",
   "metadata": {},
   "source": [
    "## Results\n",
    "* Base function ran for 17.3986 seconds\n",
    "* Optimized function ran for 11.5512 seconds\n",
    "* <strong>33.6% reduction in time to process 500 frames</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"min_length_30_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39f6fb",
   "metadata": {},
   "source": [
    "Optimization taken from this StackOverflow [answer](https://stackoverflow.com/questions/66292101/fastest-ways-to-filter-for-values-in-pandas-dataframe), which runs almost twice as fast as `df[df[\"labels\"] != -1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7efd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df[(df != -1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f987404",
   "metadata": {},
   "source": [
    "## Examine optimized profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c675a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_profile_as_df(fname):\n",
    "    with open(fname, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    arr = []\n",
    "    for l in lines:\n",
    "        if l.startswith(\"   \"):\n",
    "            split = [i.strip() for i in l.split(\"   \") if i.strip() != \"\"]\n",
    "            if len(split) == 6:\n",
    "                arr.append(split)\n",
    "        elif l.startswith(\"Line\"):\n",
    "            columns = [i.strip() for i in l.split(\"  \") if i != \"\"]\n",
    "    prof = pd.DataFrame(arr, columns=columns)\n",
    "    # set correct data types\n",
    "    prof = prof.astype({\"Line #\" : \"uint16\", \"Hits\" : \"uint16\",\n",
    "            \"Time\" : \"float64\", \n",
    "             \"Per Hit\" : \"float16\",\n",
    "            \"% Time\" : \"float16\"})\n",
    "    return prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f27c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the top 10 most time-consuming lines,\n",
      "10 are >= 1 % for 63.0 % of the time taken\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line #</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Time</th>\n",
       "      <th>Per Hit</th>\n",
       "      <th>% Time</th>\n",
       "      <th>Line Contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>88</td>\n",
       "      <td>31047</td>\n",
       "      <td>79896179.0</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>12.601562</td>\n",
       "      <td>df = df.groupby(\"labels\", as_index=False, sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>61</td>\n",
       "      <td>33837</td>\n",
       "      <td>73093371.0</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>11.601562</td>\n",
       "      <td>lines = cv2.HoughLinesP(mask, RHO, THETA, THRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>85</td>\n",
       "      <td>33711</td>\n",
       "      <td>71461387.0</td>\n",
       "      <td>2120.000000</td>\n",
       "      <td>11.296875</td>\n",
       "      <td>df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>86</td>\n",
       "      <td>33711</td>\n",
       "      <td>40139487.0</td>\n",
       "      <td>1191.000000</td>\n",
       "      <td>6.300781</td>\n",
       "      <td>df = df[(df != -1).all(axis=1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42</td>\n",
       "      <td>33838</td>\n",
       "      <td>34740119.0</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>ret, frame = cap.read()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>83</td>\n",
       "      <td>33837</td>\n",
       "      <td>27722900.0</td>\n",
       "      <td>819.500000</td>\n",
       "      <td>4.398438</td>\n",
       "      <td>df = pd.DataFrame(data)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>93</td>\n",
       "      <td>2138</td>\n",
       "      <td>25042863.0</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>df.to_csv(output_path, index=False, mode='a',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>67</td>\n",
       "      <td>56858</td>\n",
       "      <td>21365348.0</td>\n",
       "      <td>5.398438</td>\n",
       "      <td>3.400391</td>\n",
       "      <td>centroid = (int((x1 + x2) / 2), int((y1 + y2) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>103</td>\n",
       "      <td>33837</td>\n",
       "      <td>12410802.0</td>\n",
       "      <td>366.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>resized = cv2.resize(frame, (WIDTH, WIDTH))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>70</td>\n",
       "      <td>56858</td>\n",
       "      <td>11843659.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.900391</td>\n",
       "      <td>length = (x_diff * x_diff + y_diff * y_diff) *...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line #   Hits        Time      Per Hit     % Time  \\\n",
       "50      88  31047  79896179.0  2574.000000  12.601562   \n",
       "27      61  33837  73093371.0  2160.000000  11.601562   \n",
       "47      85  33711  71461387.0  2120.000000  11.296875   \n",
       "48      86  33711  40139487.0  1191.000000   6.300781   \n",
       "16      42  33838  34740119.0  1027.000000   5.500000   \n",
       "45      83  33837  27722900.0   819.500000   4.398438   \n",
       "54      93   2138  25042863.0   370.000000   4.000000   \n",
       "31      67  56858  21365348.0     5.398438   3.400391   \n",
       "61     103  33837  12410802.0   366.750000   2.000000   \n",
       "34      70  56858  11843659.0     3.000000   1.900391   \n",
       "\n",
       "                                        Line Contents  \n",
       "50  df = df.groupby(\"labels\", as_index=False, sort...  \n",
       "27  lines = cv2.HoughLinesP(mask, RHO, THETA, THRE...  \n",
       "47  df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centr...  \n",
       "48                    df = df[(df != -1).all(axis=1)]  \n",
       "16                            ret, frame = cap.read()  \n",
       "45                            df = pd.DataFrame(data)  \n",
       "54      df.to_csv(output_path, index=False, mode='a',  \n",
       "31  centroid = (int((x1 + x2) / 2), int((y1 + y2) ...  \n",
       "61        resized = cv2.resize(frame, (WIDTH, WIDTH))  \n",
       "34  length = (x_diff * x_diff + y_diff * y_diff) *...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof = read_profile_as_df(\"profiles/optimized_unlimited_profile.txt\")\n",
    "\n",
    "top = 10\n",
    "perc = 1\n",
    "largest = prof[\"% Time\"].nlargest(10)\n",
    "sub = prof.iloc[largest[largest >= perc].index, :]\n",
    "print(f\"Of the top {top} most time-consuming lines,\")\n",
    "print(f\"{sub.shape[0]} are >= {perc} % for {sub['% Time'].sum():.1f} % of the time taken\")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86030de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the top 10 most time-consuming lines,\n",
      "10 are >= 1 % for 62.5 % of the time taken\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line #</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Time</th>\n",
       "      <th>Per Hit</th>\n",
       "      <th>% Time</th>\n",
       "      <th>Line Contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>86</td>\n",
       "      <td>33712</td>\n",
       "      <td>91085206.0</td>\n",
       "      <td>2702.000000</td>\n",
       "      <td>14.101562</td>\n",
       "      <td>df = df.groupby(\"labels\", as_index=False, sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59</td>\n",
       "      <td>33838</td>\n",
       "      <td>75434282.0</td>\n",
       "      <td>2230.000000</td>\n",
       "      <td>11.601562</td>\n",
       "      <td>lines = cv2.HoughLinesP(mask, RHO, THETA, THRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>83</td>\n",
       "      <td>33712</td>\n",
       "      <td>74842692.0</td>\n",
       "      <td>2220.000000</td>\n",
       "      <td>11.601562</td>\n",
       "      <td>df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>84</td>\n",
       "      <td>33712</td>\n",
       "      <td>44580025.0</td>\n",
       "      <td>1322.000000</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>df = df[(df != -1).any(axis=1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>91</td>\n",
       "      <td>33838</td>\n",
       "      <td>29039414.0</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>df.to_csv(output_path, mode='a', header=not ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>81</td>\n",
       "      <td>33838</td>\n",
       "      <td>28808897.0</td>\n",
       "      <td>851.500000</td>\n",
       "      <td>4.398438</td>\n",
       "      <td>df = pd.DataFrame(data)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>65</td>\n",
       "      <td>56962</td>\n",
       "      <td>22308489.0</td>\n",
       "      <td>5.601562</td>\n",
       "      <td>3.400391</td>\n",
       "      <td>centroid = (int((x1 + x2) / 2), int((y1 + y2) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>100</td>\n",
       "      <td>33838</td>\n",
       "      <td>13553239.0</td>\n",
       "      <td>400.500000</td>\n",
       "      <td>2.099609</td>\n",
       "      <td>resized = cv2.resize(frame, (WIDTH, WIDTH))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>33838</td>\n",
       "      <td>12889584.0</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>frame = cv2.resize(frame, (frame.shape[1] // 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>68</td>\n",
       "      <td>56962</td>\n",
       "      <td>12489243.0</td>\n",
       "      <td>3.099609</td>\n",
       "      <td>1.900391</td>\n",
       "      <td>length = (x_diff * x_diff + y_diff * y_diff) *...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line #   Hits        Time      Per Hit     % Time  \\\n",
       "53      86  33712  91085206.0  2702.000000  14.101562   \n",
       "30      59  33838  75434282.0  2230.000000  11.601562   \n",
       "50      83  33712  74842692.0  2220.000000  11.601562   \n",
       "51      84  33712  44580025.0  1322.000000   6.898438   \n",
       "57      91  33838  29039414.0   858.000000   4.500000   \n",
       "48      81  33838  28808897.0   851.500000   4.398438   \n",
       "34      65  56962  22308489.0     5.601562   3.400391   \n",
       "63     100  33838  13553239.0   400.500000   2.099609   \n",
       "21      42  33838  12889584.0   381.000000   2.000000   \n",
       "37      68  56962  12489243.0     3.099609   1.900391   \n",
       "\n",
       "                                        Line Contents  \n",
       "53  df = df.groupby(\"labels\", as_index=False, sort...  \n",
       "30  lines = cv2.HoughLinesP(mask, RHO, THETA, THRE...  \n",
       "50  df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centr...  \n",
       "51                    df = df[(df != -1).any(axis=1)]  \n",
       "57  df.to_csv(output_path, mode='a', header=not ex...  \n",
       "48                            df = pd.DataFrame(data)  \n",
       "34  centroid = (int((x1 + x2) / 2), int((y1 + y2) ...  \n",
       "63        resized = cv2.resize(frame, (WIDTH, WIDTH))  \n",
       "21  frame = cv2.resize(frame, (frame.shape[1] // 2...  \n",
       "37  length = (x_diff * x_diff + y_diff * y_diff) *...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof = read_profile_as_df(\"profiles/optimized_fvs_unlimited_profile.txt\")\n",
    "\n",
    "largest = prof[\"% Time\"].nlargest(10)\n",
    "sub = prof.iloc[largest[largest >= perc].index, :]\n",
    "print(f\"Of the top {top} most time-consuming lines,\")\n",
    "print(f\"{sub.shape[0]} are >= {perc} % for {sub['% Time'].sum():.1f} % of the time taken\")\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
