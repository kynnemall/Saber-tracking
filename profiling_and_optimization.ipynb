{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf81c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "np.seterr(divide='ignore') # ignore divide by zero when calculating angle\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8524c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Hough Line detection\n",
    "rho = 1                 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180     # angular resolution in radians of the Hough grid\n",
    "threshold = 40          # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 25    # minimum number of pixels making up a line\n",
    "max_line_gap = 10       # maximum gap in pixels between connectable line segments\n",
    "WIDTH = 720             # width to resize the processed video to\n",
    "\n",
    "def resize(img):\n",
    "    return cv2.resize(img, (WIDTH, WIDTH))\n",
    "\n",
    "def process_video(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    ret, frame = cap.read()\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.parquet\")\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        # these channels were swapped in the notebook\n",
    "        b = (frame[:, :, 2] > 200).astype(int)\n",
    "        r = (frame[:, :, 0] > 220).astype(int)\n",
    "\n",
    "        # convert to HSV for more masking options\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = (hsv[:, :, 2] > 210).astype(int)\n",
    "        s = cv2.inRange(hsv[:, :, 1],  140, 175)\n",
    "\n",
    "        # combine masks into one\n",
    "        m1 = np.logical_and(b, s)\n",
    "        m2 = np.logical_and(r, v)\n",
    "        mask = (m1 + m2).astype(np.uint8)\n",
    "\n",
    "        # Run Hough on edge detected image\n",
    "        # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "        lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "        # process lines\n",
    "        if isinstance(lines, np.ndarray):\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line.ravel()                   \n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                x_diff = x1 - x2\n",
    "                y_diff = y1 - y2\n",
    "                length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                edge_x = 200 < centroid[0] < 1080\n",
    "                edge_y = 100 < centroid[1] < 620\n",
    "                if 100 > length > 30 and edge_x and edge_y: # length of 25 or 30\n",
    "                    degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                    data[\"frame\"].append(frame_num)\n",
    "                    data[\"centroid_x\"].append(centroid[0])\n",
    "                    data[\"centroid_y\"].append(centroid[1])\n",
    "                    data[\"angle\"].append(degrees)\n",
    "                    data[\"length\"].append(length)\n",
    "\n",
    "        # perform clustering to reduce data\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.shape[0] > 0:\n",
    "            db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]])\n",
    "            df[\"labels\"] = db.labels_\n",
    "            df = df.query(\"labels != -1\")\n",
    "            if df.shape[0] > 0:\n",
    "                df = df.groupby([\"frame\", \"labels\"], as_index=False)[[\"centroid_x\", \"centroid_y\", \"angle\"]].mean()\n",
    "                for centroid in df[[\"centroid_x\", \"centroid_y\"]].values:\n",
    "                    cv2.drawMarker(frame, centroid.astype(int), (0, 255, 0), markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "        if save_stats:\n",
    "            # Create a parquet table from your dataframe\n",
    "            table = pa.Table.from_pandas(df)\n",
    "\n",
    "            # Write direct to your parquet file\n",
    "            pq.write_to_dataset(table, root_path=output_path)\n",
    "            \n",
    "            # reset data structure\n",
    "            data = {\"frame\" : [],\n",
    "                    \"centroid_x\" : [],\n",
    "                    \"centroid_y\" : [],\n",
    "                    \"angle\" : [],\n",
    "                    \"length\" : []}\n",
    "\n",
    "        resized = resize(frame)\n",
    "        \n",
    "        if show_video:\n",
    "            cv2.imshow(\"Frame\", resized)\n",
    "        if save_video:\n",
    "            out.write(resized)\n",
    "        frame_num += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) # wait until any key is pressed\n",
    "        if frame_limit and frame_num == 500:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f process_video process_video(\"test_video.mp4\", True, \"min_length_30.avi\", False, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfdf44",
   "metadata": {},
   "source": [
    "Base function took 62 seconds to run on 500 frames (8 FPS) when `save_stats=False`; only 17 seconds when `save_stats=True` (29.4 FPS). Odd behaviour indeed.\n",
    "\n",
    "Results when saving stats:\n",
    "* 3.1 seconds (18.8%) masking with numpy\n",
    "* 0.821 seconds (5.1%) processing lines\n",
    "* 5.8 seoncds (36.8%) on clustering and DataFrame reduction\n",
    "* 0.75 seconds (4.7%) making a Parquet table and writing to file\n",
    "* The rest taken by optimized OpenCV functions\n",
    "\n",
    "These processes account for ~62% of the time taken. I think it may be possible to reduce total time taken by a third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7f65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Hough Line detection\n",
    "RHO = 1                 # distance resolution in pixels of the Hough grid\n",
    "THETA = np.pi / 180     # angular resolution in radians of the Hough grid\n",
    "THRESHOLD = 40          # minimum number of votes (intersections in Hough grid cell)\n",
    "MIN_LINE_LENGTH = 25    # minimum number of pixels making up a line\n",
    "MAX_LINE_GAP = 10       # maximum gap in pixels between connectable line segments\n",
    "WIDTH = 720             # width to resize the processed video to\n",
    "\n",
    "def optimized(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    ret, frame = cap.read()\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.csv\")\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        # these channels were swapped in the notebook\n",
    "        b = cv2.inRange(frame[:, :, 2], 200, 255)\n",
    "        r = cv2.inRange(frame[:, :, 0], 220, 255)\n",
    "\n",
    "        # convert to HSV for more masking options\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = cv2.inRange(hsv[:, :, 2], 210, 255)\n",
    "        s = cv2.inRange(hsv[:, :, 1], 140, 175)\n",
    "\n",
    "        # combine masks into one\n",
    "        m1 = cv2.bitwise_and(b, s)\n",
    "        m2 = cv2.bitwise_and(r, v)\n",
    "        mask = cv2.bitwise_or(m1, m2)\n",
    "\n",
    "        # Run Hough on masked image\n",
    "        # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "        lines = cv2.HoughLinesP(mask, RHO, THETA, THRESHOLD, np.array([]), MIN_LINE_LENGTH, MAX_LINE_GAP)\n",
    "\n",
    "        # process lines\n",
    "        if isinstance(lines, np.ndarray):\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line.ravel()\n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                x_diff = x1 - x2\n",
    "                y_diff = y1 - y2\n",
    "                length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                edge_x = 200 < centroid[0] < 1080\n",
    "                edge_y = 100 < centroid[1] < 620\n",
    "                l = 100 > length > 30\n",
    "                if l and edge_x and edge_y: # length of 25 or 30\n",
    "                    degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                    data[\"frame\"].append(frame_num)\n",
    "                    data[\"centroid_x\"].append(centroid[0])\n",
    "                    data[\"centroid_y\"].append(centroid[1])\n",
    "                    data[\"angle\"].append(degrees)\n",
    "                    data[\"length\"].append(length)\n",
    "\n",
    "        # perform clustering to reduce data\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.shape[0] > 0:\n",
    "            df[\"labels\"] = db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]].values).labels_\n",
    "            df = df[df[\"labels\"] != -1]\n",
    "            if df.shape[0] > 0:\n",
    "                df = df.groupby(\"labels\", as_index=False, sort=False).mean()\n",
    "                for centroid in df[[\"centroid_x\", \"centroid_y\"]].values:\n",
    "                    cv2.drawMarker(frame, centroid.astype(int), (0, 255, 0), markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "        if save_stats:\n",
    "            df.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "            \n",
    "            # reset data structure\n",
    "            data = {\"frame\" : [],\n",
    "                    \"centroid_x\" : [],\n",
    "                    \"centroid_y\" : [],\n",
    "                    \"angle\" : [],\n",
    "                    \"length\" : []}\n",
    "\n",
    "        resized = cv2.resize(frame, (WIDTH, WIDTH))\n",
    "        \n",
    "        if show_video:\n",
    "            cv2.imshow(\"Frame\", resized)\n",
    "        if save_video:\n",
    "            out.write(resized)\n",
    "        frame_num += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) # wait until any key is pressed\n",
    "        if frame_limit and frame_num == 500:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd643001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:13<00:00, 37.82it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f optimized optimized(\"test_video.mp4\", True, \"min_length_30.avi\", False, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a73bf",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "* Removed resize function and included in main function body\n",
    "* Replacing Parquet with Pandas CSV reduces stats saving time from 0.75 to 0.375 seconds\n",
    "* Replacing numpy masking with OpenCV functions reduces masking time from 3.1 to 0.993 seconds!\n",
    "* Replacing Pandas query with `df[df[col] != value]` reduces time from 1.7 to 0.452 seconds!\n",
    "* Removing the `frame` column as an index (since it's constant) reduces time from 1.7 to 1.2 seconds\n",
    "* Fitting DBSCAN with `.values` rather than a `DataFrame` reduces time from 1.73 to 1.14 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa7181",
   "metadata": {},
   "source": [
    "## Results\n",
    "* Base function ran for 17.3986 seconds\n",
    "* Optimized function ran for 11.5512 seconds\n",
    "* <strong>33.6% reduction in time to process 500 frames</strong>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
