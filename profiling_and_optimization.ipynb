{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525cf466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "np.seterr(divide='ignore') # ignore divide by zero when calculating angle\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aab1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Hough Line detection\n",
    "rho = 1                 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180     # angular resolution in radians of the Hough grid\n",
    "threshold = 40          # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 25    # minimum number of pixels making up a line\n",
    "max_line_gap = 10       # maximum gap in pixels between connectable line segments\n",
    "WIDTH = 720             # width to resize the processed video to\n",
    "\n",
    "def process_video(fname, save_video=False, savename=None, show_video=False, save_stats=False,\n",
    "                    frame_limit=False):\n",
    "    if savename == None:\n",
    "        savename = \"saber_tracking.avi\"\n",
    "\n",
    "    if save_video:\n",
    "        # Initialize video writer to save the results\n",
    "        out = cv2.VideoWriter(savename, cv2.VideoWriter_fourcc(*'XVID'), 30.0, \n",
    "                                 (WIDTH, WIDTH), True)\n",
    "\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    ret, frame = cap.read()\n",
    "    total_frames = 500 if frame_limit else int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "\n",
    "    output_path = savename.replace(\".avi\", \"_data.parquet\")\n",
    "    data = {\"frame\" : [],\n",
    "            \"centroid_x\" : [],\n",
    "            \"centroid_y\" : [],\n",
    "            \"angle\" : [],\n",
    "            \"length\" : []}\n",
    "\n",
    "    # instantiate DBSCAN for use throughout\n",
    "    # n_jobs parallelisation introduces too much overhead\n",
    "    db = DBSCAN(eps=5, min_samples=2)\n",
    "\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        # these channels were swapped in the notebook\n",
    "        b = (frame[:, :, 2] > 200).astype(int)\n",
    "        r = (frame[:, :, 0] > 220).astype(int)\n",
    "\n",
    "        # convert to HSV for more masking options\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = (hsv[:, :, 2] > 210).astype(int)\n",
    "        s = cv2.inRange(hsv[:, :, 1],  140, 175)\n",
    "\n",
    "        # combine masks into one\n",
    "        m1 = np.logical_and(b, s)\n",
    "        m2 = np.logical_and(r, v)\n",
    "        mask = (m1 + m2).astype(np.uint8)\n",
    "\n",
    "        # Run Hough on edge detected image\n",
    "        # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "        lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]),\n",
    "            min_line_length, max_line_gap)\n",
    "\n",
    "        # process lines\n",
    "        if isinstance(lines, np.ndarray):\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line.ravel()                   \n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                x_diff = x1 - x2\n",
    "                y_diff = y1 - y2\n",
    "                length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "                edge_x = 200 < centroid[0] < 1080\n",
    "                edge_y = 100 < centroid[1] < 620\n",
    "                if 100 > length > 30 and edge_x and edge_y: # length of 25 or 30\n",
    "                    degrees = np.rad2deg(np.arctan(y_diff / x_diff))\n",
    "                    data[\"frame\"].append(frame_num)\n",
    "                    data[\"centroid_x\"].append(centroid[0])\n",
    "                    data[\"centroid_y\"].append(centroid[1])\n",
    "                    data[\"angle\"].append(degrees)\n",
    "                    data[\"length\"].append(length)\n",
    "\n",
    "        # perform clustering to reduce data\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.shape[0] > 0:\n",
    "            db.fit(df[[\"centroid_x\", \"centroid_y\", \"angle\"]])\n",
    "            df[\"labels\"] = db.labels_\n",
    "            df = df.query(\"labels != -1\")\n",
    "            if df.shape[0] > 0:\n",
    "                df = df.groupby([\"frame\", \"labels\"], as_index=False)[\n",
    "                    [\"centroid_x\", \"centroid_y\", \"angle\"]].mean()\n",
    "                for centroid in df[[\"centroid_x\", \"centroid_y\"]].values:\n",
    "                    cv2.drawMarker(frame, centroid.astype(int), (0, 255, 0),\n",
    "                        markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "        if save_stats:\n",
    "            # Create a parquet table from your dataframe\n",
    "            table = pa.Table.from_pandas(df)\n",
    "\n",
    "            # Write direct to your parquet file\n",
    "            pq.write_to_dataset(table, root_path=output_path)\n",
    "            \n",
    "            # reset data structure\n",
    "            data = {\"frame\" : [],\n",
    "                    \"centroid_x\" : [],\n",
    "                    \"centroid_y\" : [],\n",
    "                    \"angle\" : [],\n",
    "                    \"length\" : []}\n",
    "\n",
    "        resized = cv2.resize(frame, (WIDTH, WIDTH))\n",
    "        \n",
    "        if show_video:\n",
    "            cv2.imshow(\"Frame\", resized)\n",
    "        if save_video:\n",
    "            out.write(resized)\n",
    "        frame_num += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) # wait until any key is pressed\n",
    "        if frame_limit and frame_num == 500:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if show_video:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efd66c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:56<00:00,  8.84it/s]\n"
     ]
    }
   ],
   "source": [
    "%lprun -f process_video process_video(\"test_video.mp4\", True, \"min_length_30.avi\", False, False, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
