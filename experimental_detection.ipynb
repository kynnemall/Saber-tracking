{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbe2a02",
   "metadata": {},
   "source": [
    "# Saber Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f28b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def load_image(idx=0):\n",
    "    # *** first and last channels were swapped when using OPENCV functions ***\n",
    "    vid = imageio.get_reader(\"test_video.mp4\",  'ffmpeg')\n",
    "    vid_iter = vid.iter_data()\n",
    "    for _ in range(idx+1):\n",
    "        image = next(vid_iter)\n",
    "    return image\n",
    "\n",
    "test_frames = (51, 56, 78, 104, 174, 454)\n",
    "idx = test_frames[-1]\n",
    "\n",
    "# settings for Hough Lines P\n",
    "rho = 1                         # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180             # angular resolution in radians of the Hough grid\n",
    "threshold = 40                  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 10            # minimum number of pixels making up a line\n",
    "max_line_gap = 10               # maximum gap in pixels between connectable line segments\n",
    "\n",
    "img = load_image(idx)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "px.imshow(gray > 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5a538",
   "metadata": {},
   "source": [
    "### Method 1: BGR thresholding and Hough Lines P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f71aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload image to ensure reset when running cell\n",
    "img = load_image(idx)\n",
    "\n",
    "# convert to HSV for simplicity\n",
    "blur = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "blur = cv2.filter2D(blur, ddepth=-1, kernel=kernel)\n",
    "m1 = blur[:, :, 1] > 200\n",
    "m2 = blur[:, :, 2] > 200\n",
    "m3 = blur[:, :, 0] > 240\n",
    "mask = (m1 + m2 + m3).astype(np.uint8)\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "\n",
    "gray = np.zeros(img.shape[:2], np.uint8)\n",
    "if isinstance(lines, np.ndarray):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(gray, (x1, y1), (x2, y2), 255, 2)\n",
    "            length = abs(x1 - x2) + abs(y1 - y2)\n",
    "            if 100 > length > 40:\n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                cv2.drawMarker(img, centroid, (0, 255, 0),\n",
    "                               markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "\n",
    "# contours, _ = cv2.findContours(gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# for i, contour in enumerate(contours):\n",
    "#     if 800 > cv2.contourArea(contour) > 60:\n",
    "#         cv2.drawContours(img, contours, i, 255, -1)\n",
    "        \n",
    "px.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24fa42",
   "metadata": {},
   "source": [
    "### Method 2: Combine BGR and HSV masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload image to ensure reset when running cell\n",
    "img = load_image(idx)\n",
    "\n",
    "b = (img[:, :, 0] > 200).astype(int)\n",
    "r = (img[:, :, 2] > 220).astype(int)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "v = (hsv[:, :, 2] > 210).astype(int)\n",
    "s = cv2.inRange(hsv[:, :, 1],  140, 175)\n",
    "\n",
    "m1 = np.logical_and(b, s)\n",
    "m2 = np.logical_and(r, v)\n",
    "mask = (m1 + m2).astype(np.uint8)\n",
    "\n",
    "rho = 1                         # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180             # angular resolution in radians of the Hough grid\n",
    "threshold = 40                  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 25            # minimum number of pixels making up a line\n",
    "max_line_gap = 15               # maximum gap in pixels between connectable line segments\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "\n",
    "lengths = []\n",
    "if isinstance(lines, np.ndarray):\n",
    "    for line in lines:\n",
    "        # for x1, y1, x2, y2 in line:\n",
    "        x1, y1, x2, y2 = line.ravel()\n",
    "        cv2.line(gray, (x1, y1), (x2, y2), 255, 2)\n",
    "        x_diff = x1 - x2\n",
    "        y_diff = y1 - y2\n",
    "        length = (x_diff * x_diff + y_diff * y_diff) ** 0.5\n",
    "        lengths.append(length)\n",
    "        centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        if 100 > length > 70:\n",
    "            # cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), thickness=2)\n",
    "            # cv2.drawMarker(img, centroid, (0, 255, 0),\n",
    "            #                markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "            cv2.putText(img, f\"{length:.0f}\", centroid, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        color=(0, 0, 255), fontScale=1, thickness=2)\n",
    "        \n",
    "px.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aff22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line characteristics\n",
    "px.histogram(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e87f39",
   "metadata": {},
   "source": [
    "### Method 3: Grayscale clustering and thresholding\n",
    "\n",
    "K-means clustering on image data is a good way to cluster colors. Speed could be an issue, but this would be an excellent way to accuractely detect lines in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19602b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload image to ensure reset when running cell\n",
    "img = load_image(idx)\n",
    "\n",
    "img = cv2.resize(img, (180, 320)) # smallest size for accurate saber detection\n",
    "image_2D = img.reshape(-1, 3)\n",
    "pixel_values = np.float32(image_2D) # must be type float32\n",
    "\n",
    "# below from: https://www.thepythoncode.com/article/kmeans-for-image-segmentation-opencv-python\n",
    "# stopping criteria\n",
    "# criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "# _, labels, (centers) = cv2.kmeans(pixel_values, 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# # convert back to 8 bit values\n",
    "# centers = np.uint8(centers)\n",
    "\n",
    "# # flatten the labels array\n",
    "# labels = labels.flatten()\n",
    "\n",
    "# segmented_image = centers[labels.flatten()]\n",
    "# segmented_image = segmented_image.reshape(img.shape)\n",
    "\n",
    "# sklearn method\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(image_2D)\n",
    "clustered = kmeans.cluster_centers_[kmeans.labels_]\n",
    "clustered_3D = clustered.reshape(img.shape[0], img.shape[1], img.shape[2])\n",
    "mask = cv2.cvtColor(clustered_3D.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "mask = (mask > 150).astype(np.uint8)\n",
    "\n",
    "# settings for Hough Lines P\n",
    "rho = 1                         # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180             # angular resolution in radians of the Hough grid\n",
    "threshold = 40                  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 40            # minimum number of pixels making up a line\n",
    "max_line_gap = 10               # maximum gap in pixels between connectable line segments\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(mask, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "\n",
    "gray = np.zeros(img.shape[:2], np.uint8)\n",
    "if isinstance(lines, np.ndarray):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(gray, (x1, y1), (x2, y2), 255, 2)\n",
    "            length = abs(x1 - x2) + abs(y1 - y2)\n",
    "            if 100 > length > 40:\n",
    "                centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                cv2.drawMarker(img, centroid, (0, 255, 0),\n",
    "                               markerType=cv2.MARKER_CROSS, thickness=2)\n",
    "                \n",
    "px.imshow(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
